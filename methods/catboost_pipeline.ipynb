{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83f62858",
   "metadata": {},
   "source": [
    "# Попытка применить Catboost*\n",
    "\n",
    "*попытка неудачная, ниже опишу подробнее почему"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d147fb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "np.random.seed(2025)\n",
    "import typing as t\n",
    "import matplotlib.pyplot as plt\n",
    "from abc import ABC, abstractmethod\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import HTML\n",
    "from dataclasses import dataclass\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce9c68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"/home/gleb_galagan/tbank_recsys/sirius_recsys/sirius-2025-recsys/data/\"\n",
    "train = pl.read_parquet(data_folder + \"train.pq\")\n",
    "books = pl.read_parquet('/home/gleb_galagan/tbank_recsys/baseline_solution/books_all_embs.parquet')\n",
    "# books_descr = pl.read_parquet('/home/gleb_galagan/tbank_recsys/baseline_solution/books_title_description_emb.parquet')\n",
    "test_exploded = pl.read_parquet(data_folder + \"test.pq\")\n",
    "test = test_exploded.group_by(\"user_id\", maintain_order=True).agg(pl.col(\"item_id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b3d05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "\n",
    "def extract_embeddings_to_array(df, embedding_col):\n",
    "    \"\"\"Extract embeddings from polars DataFrame to numpy array\"\"\"\n",
    "    embeddings = []\n",
    "    for row in df.iter_rows():\n",
    "        embed = row[df.columns.index(embedding_col)]\n",
    "        if embed is not None and len(embed) > 0:\n",
    "            embeddings.append(np.array(embed, dtype=np.float32))\n",
    "        else:\n",
    "            # Handle missing embeddings with zeros\n",
    "            embeddings.append(np.zeros(1024, dtype=np.float32))  # Assuming 1024 is original dim\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "\n",
    "def reduce_embeddings_pca(books_df, embedding_columns, n_components=64):\n",
    "    \"\"\"\n",
    "    Уменьшаем размер эмбеддингов с помощью PCA\n",
    "    \"\"\"\n",
    "    print(f\"Reducing embeddings to {n_components} dimensions using PCA...\")\n",
    "    \n",
    "    books_reduced = books_df.clone()\n",
    "    \n",
    "    for col in embedding_columns:\n",
    "        print(f\"Processing {col}...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Extract embeddings to numpy array\n",
    "        embeddings = extract_embeddings_to_array(books_df, col)\n",
    "        \n",
    "        # Standardize before PCA (recommended)\n",
    "        scaler = StandardScaler()\n",
    "        embeddings_scaled = scaler.fit_transform(embeddings)\n",
    "        \n",
    "        # Apply PCA\n",
    "        pca = PCA(n_components=n_components, random_state=42)\n",
    "        embeddings_reduced = pca.fit_transform(embeddings_scaled)\n",
    "        \n",
    "        # Convert back to list format for polars\n",
    "        embeddings_list = [emb.tolist() for emb in embeddings_reduced]\n",
    "        \n",
    "        # Replace in dataframe\n",
    "        new_col_name = f\"{col}_pca_{n_components}\"\n",
    "        books_reduced = books_reduced.with_columns(\n",
    "            pl.Series(embeddings_list).alias(new_col_name)\n",
    "        ).drop(col)\n",
    "        \n",
    "        print(f\"  {col} -> {new_col_name}: {time.time() - start_time:.2f}s\")\n",
    "        print(f\"  Explained variance ratio: {pca.explained_variance_ratio_.sum():.3f}\")\n",
    "    \n",
    "    return books_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf09bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_columns = ['image_embedding', 'description_embeddings']\n",
    "\n",
    "books = reduce_embeddings_pca(books.clone(), embedding_columns, n_components=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30fbd91",
   "metadata": {},
   "source": [
    "## 1. Сплитим данные на train и val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cca58a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from datetime import timedelta\n",
    "\n",
    "# Extract the scalar value from the DataFrame\n",
    "last_date = train.select(pl.col('date_added')).max().item()\n",
    "threshold = last_date - timedelta(days=40)\n",
    "\n",
    "train = train.with_columns(\n",
    "    pl.col('is_read').cast(pl.Int8).alias('is_read')\n",
    ")\n",
    "train_set = train.filter(pl.col('date_added') <= threshold)\n",
    "val_set = train.filter(pl.col('date_added') > threshold)\n",
    "print(train_set.shape, val_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f397726a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_books = set(train_set['item_id'].unique())\n",
    "\n",
    "# Делим айтемы без даталиков, только те что есть в val_set\n",
    "books_train_only = books.filter(pl.col('item_id').is_in(train_books))\n",
    "\n",
    "train_set = train_set.join(\n",
    "    books_train_only.select(['item_id', 'embedding_tags', 'description_embeddings_pca_64', 'image_embedding_pca_64']), \n",
    "    on='item_id', \n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "val_set = val_set.join(\n",
    "    books_train_only.select(['item_id', 'embedding_tags', 'description_embeddings_pca_64', 'image_embedding_pca_64']), \n",
    "    on='item_id', \n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8d6f8a",
   "metadata": {},
   "source": [
    "**Ключевой момент** вот мы здесь понимаем что у нас нет чисто фичей юзера и нам нужно джоинить интеракции юзеров с айтемами. **Но как же быть с более чем 3к книг без интеракций**\n",
    "\n",
    "Отсюда следуюет то что мы не сможем решить проблему холодного старта с имеющимися фичами и катбустом. Если бы еще у юзеров были свои фичи. \n",
    "\n",
    "**Future work**: можно попробовать подать описание(фича decription) прочитанных книг их названия, теги, LLMке чтобы она составила примерный портрет юзера, полученные текстовые описания можно векторизовать текстовым энкодером *(можно попробовать но время движется к дедлайну)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1be5db",
   "metadata": {},
   "source": [
    "### Приводим к типу данных для Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff73f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRanker, Pool\n",
    "from copy import deepcopy\n",
    "train_set = train_set.to_pandas()\n",
    "val_set = val_set.to_pandas()\n",
    "\n",
    "feature_columns = ['is_read','embedding_tags', 'description_embeddings_pca_64', 'image_embedding_pca_64']\n",
    "\n",
    "# data_train = train_set.drop('rating', axis=1)\n",
    "train_set = train_set.sort_values('user_id')\n",
    "val_set = val_set.sort_values('user_id')\n",
    "\n",
    "data_train = train_set[feature_columns]\n",
    "label_train = train_set['rating']\n",
    "\n",
    "group_train = train_set['user_id'].values\n",
    "\n",
    "# data_val = val_set.drop('rating', axis=1)\n",
    "data_val = val_set[feature_columns]  # Exclude user_id from features\n",
    "label_val = val_set['rating']\n",
    "group_val = val_set['user_id'].values\n",
    "\n",
    "\n",
    "train_pool = Pool(\n",
    "    data=data_train,\n",
    "    label=label_train,\n",
    "    group_id=group_train,\n",
    "    embedding_features=['embedding_tags', 'description_embeddings_pca_64', 'image_embedding_pca_64']\n",
    ")\n",
    "\n",
    "\n",
    "embedding_dim_tags = len(data_val[\"embedding_tags\"].iloc[0])\n",
    "embedding_dim_images = len(data_val[\"image_embedding_pca_64\"].iloc[0])\n",
    "embedding_dim_description = len(data_val[\"description_embeddings_pca_64\"].iloc[0])\n",
    "\n",
    "def fix_embedding(x, embedding_dim):\n",
    "    if isinstance(x, (list, np.ndarray)):\n",
    "        arr = np.array(x, dtype=np.float32)\n",
    "        if arr.shape[0] != embedding_dim:\n",
    "            print('Err')\n",
    "            return np.zeros(embedding_dim, dtype=np.float32)\n",
    "        return arr\n",
    "    else:\n",
    "        return np.zeros(embedding_dim, dtype=np.float32)\n",
    "\n",
    "data_val[\"embedding_tags\"] = data_val[\"embedding_tags\"].apply(\n",
    "    fix_embedding, args=(embedding_dim_tags,)\n",
    ")\n",
    "data_val[\"image_embedding_pca_64\"] = data_val[\"image_embedding_pca_64\"].apply(\n",
    "    fix_embedding, args=(embedding_dim_images,)\n",
    ")\n",
    "data_val[\"description_embeddings_pca_64\"] = data_val[\"description_embeddings_pca_64\"].apply(\n",
    "    fix_embedding, args=(embedding_dim_description,)\n",
    ")\n",
    "\n",
    "val_pool = Pool(\n",
    "    data=data_val,\n",
    "    label=label_val,\n",
    "    group_id=group_val,\n",
    "    embedding_features=['embedding_tags', 'description_embeddings_pca_64', 'image_embedding_pca_64']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0546a80f",
   "metadata": {},
   "source": [
    "## Обучаем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddff4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_parameters = {\n",
    "    'iterations': 100,\n",
    "    'custom_metric': ['NDCG', 'PFound', 'AverageGain:top=10'],\n",
    "    'verbose': True,\n",
    "    'random_seed': 42,\n",
    "    'learning_rate': 0.1,\n",
    "    'depth': 4,\n",
    "    'early_stopping_rounds': 30, \n",
    "    'thread_count': num_cores\n",
    "}\n",
    "\n",
    "parameters = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160ab823",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fit_model(loss_function, additional_params=None, train_pool=train_pool, val_pool=val_pool):\n",
    "    parameters = deepcopy(default_parameters)\n",
    "    parameters['loss_function'] = loss_function\n",
    "    parameters['train_dir'] = loss_function\n",
    "\n",
    "    if additional_params is not None:\n",
    "        parameters.update(additional_params)\n",
    "\n",
    "    model = CatBoostRanker(**parameters)\n",
    "    model.fit(train_pool, eval_set=val_pool, plot=False)\n",
    "    # model.fit(train_pool, eval_set=val_pool, plot=True)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f43d7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rmse = fit_model('RMSE', {'custom_metric': ['PrecisionAt:top=10', 'RecallAt:top=10', 'MAP:top=10']})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc39d1f5",
   "metadata": {},
   "source": [
    "## 2. Сохраняем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b7f40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def save_catboost_model(model, filepath: str):\n",
    "    \"\"\"Save a CatBoost model to file.\"\"\"\n",
    "    os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "    model.save_model(filepath)\n",
    "    print(f\"Model saved to {filepath}\")\n",
    "\n",
    "def load_catboost_model(filepath: str) -> CatBoostRanker:\n",
    "    \"\"\"Load a CatBoost model from file.\"\"\"\n",
    "    model = CatBoostRanker()\n",
    "    model.load_model(filepath)\n",
    "    print(f\"Model loaded from {filepath}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8341cc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_catboost_model(model_rmse, \"models/catboost_ranker_rmse.cbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71e184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_catboost_model(\"models/catboost_ranker_rmse.cbm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96050bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "explainer = shap.Explainer(loaded_model)\n",
    "\n",
    "shap_values = explainer.shap_values(train_pool)\n",
    "shap.summary_plot(shap_values, data_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1e45af",
   "metadata": {},
   "source": [
    "Видим то что основной фичей здесь выступает is_read, а наши эмбеддинги эмбеддинги сильно менее важные (несмотря на то что одно: легкая бинарная фича, а другие это тяжелые эмбединги)\n",
    "\n",
    "Т.е. несмотря на то что мы подали фичи эмбеддингов корректно (в embedding_features) но все равно их importance низкий"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80359f9",
   "metadata": {},
   "source": [
    "## 3. Тестируем модель на тестовой выборке\n",
    "Для экономии компьюта и времени берем сэмпл из 100 user_id но при этом берем все книги. Считаем скор для каждой пары юзер-айтем\n",
    "\n",
    "Также мы добавляем implicit фичу is_read, чтобы по чисто контентным фичам Catboost не выдал всем одинаковый список (получается как Popular но дороже, так как оценен Catboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0c62ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import Pool\n",
    "import polars as pl\n",
    "\n",
    "\n",
    "# Берем все интеракции трейн + вал  и все фичи с которыми есть интеракции\n",
    "full_items = train.join(\n",
    "    books.select(['item_id', 'embedding_tags', 'description_embeddings_pca_64', 'image_embedding_pca_64']), \n",
    "    on='item_id', \n",
    "    how=\"left\"\n",
    ")\n",
    "# Дропаем таргет и временную фичу\n",
    "full_items = full_items.drop(['rating', 'date_added'])\n",
    "\n",
    "user_ids = test.drop('item_id')['user_id'].unique()\n",
    "\n",
    "items_features = books.select(['item_id', 'embedding_tags', 'description_embeddings_pca_64', 'image_embedding_pca_64'])\n",
    "\n",
    "# Helper to fix embeddings\n",
    "def fix_embedding(x, dim):\n",
    "    if x is None or (isinstance(x, float) and np.isnan(x)):\n",
    "        return np.zeros(dim, dtype=np.float32)\n",
    "    try:\n",
    "        arr = np.array(x, dtype=np.float32)\n",
    "        if arr.ndim == 0:  # scalar, not array\n",
    "            return np.zeros(dim, dtype=np.float32)\n",
    "        if arr.shape[0] != dim:\n",
    "            return np.zeros(dim, dtype=np.float32)\n",
    "        return arr\n",
    "    except Exception:\n",
    "        return np.zeros(dim, dtype=np.float32)\n",
    "\n",
    "# Get dimensions from a sample\n",
    "sample_item = items_features.to_pandas().iloc[0]\n",
    "dim_tags = len(sample_item[\"embedding_tags\"])\n",
    "dim_desc = len(sample_item[\"description_embeddings_pca_64\"])\n",
    "dim_img = len(sample_item[\"image_embedding_pca_64\"])\n",
    "\n",
    "topk = 50\n",
    "results = []\n",
    "\n",
    "for idx, uid in enumerate(np.array(user_ids)[:100]):\n",
    "    # Берем все взаимодействия юзера\n",
    "    user_history = full_items.filter(pl.col('user_id') == uid)\n",
    "    \n",
    "    # Берем все уникальные айтемы\n",
    "    all_items = full_items['item_id'].unique()\n",
    "    \n",
    "    # строим комбинацию юзер - айтем\n",
    "    user_items_df = pl.DataFrame({\n",
    "        'item_id': all_items,\n",
    "        'user_id': [uid] * len(all_items)\n",
    "    })\n",
    "    \n",
    "    # 4. Merge with user's reading history to get is_read values\n",
    "    \n",
    "    user_items_df = user_items_df.join(\n",
    "        user_history.select(['item_id', 'is_read']),\n",
    "        on='item_id',\n",
    "        how='left'\n",
    "    ).with_columns(\n",
    "        pl.col('is_read').fill_null(False)  # Items not in history are unread\n",
    "    )\n",
    "    \n",
    "    # 5. Merge with item features\n",
    "    user_items_df = user_items_df.join(\n",
    "        items_features,\n",
    "        on='item_id',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    user_items = user_items_df.to_pandas()\n",
    "    \n",
    "    # 7. Fix embeddings\n",
    "    user_items[\"embedding_tags\"] = user_items[\"embedding_tags\"].apply(fix_embedding, args=(dim_tags,))\n",
    "    user_items[\"description_embeddings_pca_64\"] = user_items[\"description_embeddings_pca_64\"].apply(fix_embedding, args=(dim_desc,))\n",
    "    user_items[\"image_embedding_pca_64\"] = user_items[\"image_embedding_pca_64\"].apply(fix_embedding, args=(dim_img,))\n",
    "    \n",
    "    # print(f\"User {uid} - Items read: {user_items['is_read'].sum()}, Total items: {len(user_items)}\")\n",
    "    \n",
    "    pool = Pool(\n",
    "        data=user_items[feature_columns],\n",
    "        group_id=user_items[\"user_id\"].values,\n",
    "        embedding_features=[\n",
    "            \"embedding_tags\",\n",
    "            \"description_embeddings_pca_64\",\n",
    "            \"image_embedding_pca_64\"\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    preds = loaded_model.predict(pool)\n",
    "    user_items[\"score\"] = preds\n",
    "    \n",
    "    # 11. Keep only top-K\n",
    "    top_items = (\n",
    "        user_items.nlargest(topk, \"score\")[[\"user_id\", \"item_id\", \"score\"]]\n",
    "    )\n",
    "    results.append(top_items)\n",
    "    \n",
    "    # Progress indicator\n",
    "    if idx % 10 == 0:  # More frequent for debugging\n",
    "        print(f\"Processed {idx} users\")\n",
    "\n",
    "# Final recommendations\n",
    "recommendations = pd.concat(results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9008a4a1",
   "metadata": {},
   "source": [
    "## 4. Считаем метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1565125f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_books = books.shape[0]\n",
    "print(f\"N books: {n_books}\")\n",
    "\n",
    "n_cold_books = n_books - train[\"item_id\"].n_unique()\n",
    "print(f\"N 'cold' books: {n_cold_books}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b7d19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACHTUNG! DO NOT TOUCH\n",
    "\n",
    "@dataclass\n",
    "class AtKMetric(ABC):\n",
    "    k: int\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def name(self) -> str:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @property\n",
    "    def full_name(self) -> str:\n",
    "        return f\"{self.name}@{self.k}\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def __call__(self, *, preds_col: str = \"preds\", ground_truth_col: str = \"ground_truth\", **kwargs) -> pl.Expr:\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class NDCG(AtKMetric):\n",
    "    @property\n",
    "    def name(self) -> str:\n",
    "        return \"ndcg\"\n",
    "\n",
    "    def __call__(self, *, preds_col: str = \"preds\", ground_truth_col: str = \"ground_truth\", **kwargs) -> pl.Expr:\n",
    "        def _dcg(scores: np.ndarray) -> float:\n",
    "            # Handle empty arrays\n",
    "            if len(scores) == 0:\n",
    "                return 0.0\n",
    "            # Use vectorized operations for better performance\n",
    "            positions = np.arange(1, len(scores) + 1, dtype=np.float64)\n",
    "            return np.sum((np.power(2, scores) - 1) / np.log2(positions + 1))\n",
    "\n",
    "        def ndcg(predicted: list[t.Any], gt_items: list[t.Any]) -> float:\n",
    "            # Handle empty predictions or ground truth\n",
    "            if not predicted or not gt_items:\n",
    "                return 0.0\n",
    "                \n",
    "            # Take only top-k predictions\n",
    "            predicted = predicted[:self.k]\n",
    "            \n",
    "            # Create relevance scores (1 for relevant items, 0 otherwise)\n",
    "            relevance = np.array([1 if x in gt_items else 0 for x in predicted], dtype=np.float64)\n",
    "            \n",
    "            rank_dcg = _dcg(relevance)\n",
    "            if rank_dcg == 0.0:\n",
    "                return 0.0\n",
    "                \n",
    "            # Ideal DCG: sort ground truth by relevance (all 1s) and take top-k\n",
    "            ideal_relevance = np.ones(min(len(gt_items), self.k), dtype=np.float64)\n",
    "            ideal_dcg = _dcg(ideal_relevance)\n",
    "            \n",
    "            if ideal_dcg == 0.0:\n",
    "                return 0.0\n",
    "                \n",
    "            return rank_dcg / ideal_dcg\n",
    "\n",
    "        return pl.struct([preds_col, ground_truth_col]).map_elements(\n",
    "            lambda x: ndcg(x[preds_col], x[ground_truth_col]),\n",
    "            return_dtype=pl.Float64\n",
    "        ).alias(self.full_name)\n",
    "\n",
    "\n",
    "class Recall(AtKMetric):\n",
    "    @property\n",
    "    def name(self) -> str:\n",
    "        return \"recall\"\n",
    "\n",
    "    def __call__(self, *, preds_col: str = \"preds\", ground_truth_col: str = \"ground_truth\", **kwargs) -> pl.Expr:\n",
    "        def recall(predicted: list[t.Any], gt_items: list[t.Any]) -> float:\n",
    "            # Handle empty ground truth\n",
    "            if not gt_items:\n",
    "                return 0.0\n",
    "                \n",
    "            # Take only top-k predictions\n",
    "            predicted = predicted[:self.k]\n",
    "            \n",
    "            # Calculate intersection\n",
    "            intersection = len(set(gt_items).intersection(set(predicted)))\n",
    "            return intersection / len(gt_items)\n",
    "\n",
    "        return pl.struct([preds_col, ground_truth_col]).map_elements(\n",
    "            lambda x: recall(x[preds_col], x[ground_truth_col]),\n",
    "            return_dtype=pl.Float64\n",
    "        ).alias(self.full_name)\n",
    "\n",
    "# ==================\n",
    "# Новая метрика ARP\n",
    "# ==================\n",
    "class ARP(AtKMetric):\n",
    "    \"\"\"\n",
    "    Calculates the Average Recommendation Popularity (ARP).\n",
    "    This metric measures the average popularity of the recommended items.\n",
    "    A lower ARP suggests the model is recommending less obvious, \"long-tail\" items.\n",
    "    \"\"\"\n",
    "    @property\n",
    "    def name(self) -> str:\n",
    "        return \"arp\"\n",
    "\n",
    "    def __call__(self, *, preds_col: str = \"preds\", ground_truth_col: str = \"ground_truth\", item_popularity_map: dict[t.Any, float] | None = None, **kwargs) -> pl.Expr:\n",
    "        if item_popularity_map is None:\n",
    "            raise ValueError(\"item_popularity_map is required for ARP metric\")\n",
    "\n",
    "        def arp(predicted: list[t.Any]) -> float:\n",
    "            if isinstance(predicted, pl.Series):\n",
    "                predicted = predicted.to_list()\n",
    "            if not predicted:\n",
    "                return 0.0\n",
    "            \n",
    "            predicted = predicted[:self.k]\n",
    "            \n",
    "            # Get popularities, default to 0 if item not in map\n",
    "            popularities = [item_popularity_map.get(item, 0.0) for item in predicted]\n",
    "            \n",
    "            if not popularities:\n",
    "                return 0.0\n",
    "                \n",
    "            return sum(popularities) / len(popularities)\n",
    "\n",
    "        # Note: ground_truth_col is not used but is part of the abstract method signature.\n",
    "        return pl.col(preds_col).map_elements(\n",
    "            lambda p: arp(p),\n",
    "            return_dtype=pl.Float64\n",
    "        ).alias(self.full_name)\n",
    "# ==============\n",
    "# Новая метрика Serndipity\n",
    "# ==============\n",
    "class Serendipity(AtKMetric):\n",
    "    \"\"\"\n",
    "    Calculates Serendipity.\n",
    "    This metric rewards recommendations that are both relevant (in ground truth)\n",
    "    and surprising (unpopular). The score for a user is the sum of (1 - popularity)\n",
    "    for each correctly recommended item.\n",
    "    \"\"\"\n",
    "    @property\n",
    "    def name(self) -> str:\n",
    "        return \"serendipity\"\n",
    "\n",
    "    def __call__(self, *, preds_col: str = \"preds\", ground_truth_col: str = \"ground_truth\", item_popularity_map: dict[t.Any, float] | None = None, **kwargs) -> pl.Expr:\n",
    "        if item_popularity_map is None:\n",
    "            raise ValueError(\"item_popularity_map is required for Serendipity metric\")\n",
    "\n",
    "        def serendipity(predicted: list[t.Any], gt_items: list[t.Any]) -> float:\n",
    "            if not predicted or not gt_items:\n",
    "                return 0.0\n",
    "                \n",
    "            predicted = predicted[:self.k]\n",
    "            \n",
    "            # Find relevant recommended items\n",
    "            relevant_preds = set(predicted).intersection(set(gt_items))\n",
    "            \n",
    "            if not relevant_preds:\n",
    "                return 0.0\n",
    "                \n",
    "            # Score is the sum of (1 - popularity) for each relevant item\n",
    "            score = sum(1 - item_popularity_map.get(item, 0.0) for item in relevant_preds)\n",
    "            \n",
    "            # Normalize by k to get an average serendipity score per recommendation slot\n",
    "            return score / self.k\n",
    "\n",
    "        return pl.struct([preds_col, ground_truth_col]).map_elements(\n",
    "            lambda x: serendipity(x[preds_col], x[ground_truth_col]),\n",
    "            return_dtype=pl.Float64\n",
    "        ).alias(self.full_name)\n",
    "\n",
    "\n",
    "\n",
    "def coverage(df: pl.DataFrame, n_items_in_catalog: int, preds_col: str = \"preds\") -> float:\n",
    "    if n_items_in_catalog <= 0:\n",
    "        return 0.0\n",
    "        \n",
    "    unique_recommended = df.select(\n",
    "        pl.col(preds_col).explode().n_unique()\n",
    "    ).item()\n",
    "    return unique_recommended / n_items_in_catalog\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_extended(\n",
    "    df: pl.DataFrame,\n",
    "    model_preds_col: str,\n",
    "    ground_truth_col: str = \"item_id\",\n",
    "    n_items_in_catalog: int = n_books,\n",
    "    k: int = 10,\n",
    "    train_df: pl.DataFrame | None = None,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Расширенная функция расчета метрик. Здесь добавлены ARP и Serendipity. Для расчета этих метрик считаем матрицу популярности. \n",
    "    \"\"\"\n",
    "    # Compute item_popularity_map from train_df\n",
    "    item_popularity_map = None\n",
    "    if train_df is not None:\n",
    "        total_interactions = train_df.height\n",
    "        if total_interactions > 0:\n",
    "            item_popularity_map = dict(\n",
    "                train_df\n",
    "                .group_by(\"item_id\")\n",
    "                .agg(pl.count().alias(\"count\"))\n",
    "                .with_columns((pl.col(\"count\") / total_interactions).alias(\"popularity\"))\n",
    "                .select([\"item_id\", \"popularity\"])\n",
    "                .iter_rows()\n",
    "            )\n",
    "    \n",
    "\n",
    "    metrics = [\n",
    "        NDCG(k=k),\n",
    "        Recall(k=k),\n",
    "    ]\n",
    "\n",
    "    # Add popularity-based metrics if the map is available\n",
    "    if item_popularity_map:\n",
    "        metrics.extend([\n",
    "            ARP(k=k),\n",
    "            Serendipity(k=k),\n",
    "        ])\n",
    "\n",
    "    result = {}\n",
    "    result_df = df.clone()\n",
    "\n",
    "\n",
    "    for metric in metrics:\n",
    "        # NEW: Prepare kwargs for the metric, including popularity map if needed\n",
    "        metric_kwargs = {\n",
    "            \"preds_col\": model_preds_col,\n",
    "            \"ground_truth_col\": ground_truth_col,\n",
    "        }\n",
    "        if isinstance(metric, (ARP, Serendipity)):\n",
    "            if not item_popularity_map:\n",
    "                # This check is for safety, but the logic should prevent this\n",
    "                continue\n",
    "            metric_kwargs[\"item_popularity_map\"] = item_popularity_map\n",
    "\n",
    "        # NEW: Calculate the metric using the prepared kwargs\n",
    "        result_df = result_df.with_columns(\n",
    "            metric(**metric_kwargs)\n",
    "        )\n",
    "        result[f\"{metric.full_name}\"] = round(\n",
    "            result_df.select(pl.col(metric.full_name).mean()).item(), 3\n",
    "        )\n",
    "\n",
    "    if n_items_in_catalog is not None:\n",
    "        result[f\"coverage\"] = round(\n",
    "            coverage(result_df, n_items_in_catalog, preds_col=model_preds_col), 3\n",
    "        )\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62459d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_extended_with_cold_split(\n",
    "    df: pl.DataFrame,\n",
    "    model_preds_col: str,\n",
    "    ground_truth_col: str = \"item_id\",\n",
    "    cold_items: set[int] | None = None,\n",
    "    n_items_in_catalog: int | None = None,\n",
    "    k: int = 10,\n",
    "    train_df: pl.DataFrame | None = train, # NEW: Added train_df to calculate popularity\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Calculates metrics splitting users by whether they have \"cold\" items in their ground truth.\n",
    "    Also calculates ARP and Serendipity if train_df is provided.\n",
    "    \"\"\"\n",
    "    # NEW: Calculate item_popularity_map from train_df for ARP and Serendipity\n",
    "    item_popularity_map = None\n",
    "    if train_df is not None:\n",
    "        total_interactions = train_df.height\n",
    "        if total_interactions > 0:\n",
    "            item_popularity_map = dict(\n",
    "                train_df\n",
    "                .group_by(\"item_id\")\n",
    "                .agg(pl.count().alias(\"count\"))\n",
    "                .with_columns((pl.col(\"count\") / total_interactions).alias(\"popularity\"))\n",
    "                .select([\"item_id\", \"popularity\"])\n",
    "                .iter_rows()\n",
    "            )\n",
    "\n",
    "    # NEW: Conditionally add ARP and Serendipity to the metrics list\n",
    "    metrics = [NDCG(k=k), Recall(k=k)]\n",
    "    if item_popularity_map:\n",
    "        metrics.extend([\n",
    "            ARP(k=k),\n",
    "            Serendipity(k=k),\n",
    "        ])\n",
    "\n",
    "    result = {}\n",
    "\n",
    "    if not cold_items:\n",
    "        # Handle case where cold_items is not provided to avoid errors\n",
    "        print(\"Warning: `cold_items` set is not provided. Cannot perform cold/warm split.\")\n",
    "        return result\n",
    "\n",
    "    # Mark rows that have cold items in their ground_truth\n",
    "    df = df.with_columns(\n",
    "        pl.col(ground_truth_col)\n",
    "        .list.eval(pl.element().is_in(cold_items))\n",
    "        .list.any()\n",
    "        .alias(\"has_cold\")\n",
    "    )\n",
    "\n",
    "    # Calculate metrics for each split\n",
    "    for split_name, mask in [(\"cold\", pl.col(\"has_cold\")),\n",
    "                             (\"warm\", ~pl.col(\"has_cold\"))]:\n",
    "        split_df = df.filter(mask)\n",
    "        if split_df.height == 0:\n",
    "            print(f\"No data for '{split_name}' split, skipping.\")\n",
    "            continue\n",
    "\n",
    "        for metric in metrics:\n",
    "            # NEW: Prepare kwargs for the metric, including popularity map if needed\n",
    "            metric_kwargs = {\n",
    "                \"preds_col\": model_preds_col,\n",
    "                \"ground_truth_col\": ground_truth_col,\n",
    "            }\n",
    "            if isinstance(metric, (ARP, Serendipity)):\n",
    "                if not item_popularity_map:\n",
    "                    # This check is for safety, but the logic should prevent this\n",
    "                    continue\n",
    "                metric_kwargs[\"item_popularity_map\"] = item_popularity_map\n",
    "\n",
    "            # NEW: Calculate the metric using the prepared kwargs\n",
    "            split_df = split_df.with_columns(\n",
    "                metric(**metric_kwargs)\n",
    "            )\n",
    "            result[f\"{metric.full_name}_{split_name}\"] = round(\n",
    "                split_df.select(pl.col(metric.full_name).mean()).item(), 3\n",
    "            )\n",
    "\n",
    "        if n_items_in_catalog is not None:\n",
    "            result[f\"coverage_{split_name}\"] = round(\n",
    "                coverage(split_df, n_items_in_catalog, preds_col=model_preds_col), 3\n",
    "            )\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9b5400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top10_recommendations(df):\n",
    "    \"\"\"\n",
    "    Generate top-10 item recommendations for each user based on model predictions\n",
    "    \"\"\"\n",
    "    # Sort by user_id and score (descending)\n",
    "    df_sorted = df.sort_values(['user_id', 'score'], ascending=[True, False])\n",
    "    \n",
    "    # Get top-10 items for each user\n",
    "    top10_recs = (df_sorted\n",
    "                  .groupby('user_id')['item_id']\n",
    "                  .apply(lambda x: list(x.head(10)))\n",
    "                  .reset_index())\n",
    "    \n",
    "    top10_recs.columns = ['user_id', 'preds']  # Rename for consistency\n",
    "    return top10_recs\n",
    "\n",
    "top10_recommendations = get_top10_recommendations(recommendations)\n",
    "print(top10_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ccad4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = test.filter(pl.col(\"user_id\").is_in(np.array(user_ids[:100])))\n",
    "\n",
    "test_recommendations = pl.from_pandas(top10_recommendations)\n",
    "test_res = (\n",
    "            test.lazy()\n",
    "            .join(test_recommendations.lazy().select(['user_id','preds']), on='user_id', how=\"left\")\n",
    "            .collect()\n",
    "        )\n",
    "\n",
    "\n",
    "catboost_ov = evaluate_extended(df=test_res, model_preds_col=\"preds\")\n",
    "\n",
    "catboost_ov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfdf6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_split = evaluate_extended_with_cold_split(df=test_res, model_preds_col=\"preds\")\n",
    "catboost_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ec5309",
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_res_ov = {}\n",
    "catboost_res_split = {}\n",
    "catboost_res_ov['catboost_res'] = catboost_ov\n",
    "catboost_res_split['catboost_res'] = catboost_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380ebce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_res_ov_pd = pd.DataFrame(catboost_res_ov)\n",
    "catboost_res_split_pd = pd.DataFrame(catboost_res_split)\n",
    "catboost_res_ov_pd.to_csv('results/catboost_res_ov.csv')\n",
    "catboost_res_split_pd.to_csv('results/catboost_res_split.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfcd204",
   "metadata": {},
   "source": [
    "## EDA предсказаний и оценка "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0869c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Flatten recommendations properly\n",
    "flat_recs = test_res.select(pl.col(\"preds\").explode().alias(\"item_id\"))\n",
    "\n",
    "# 2. Count frequencies\n",
    "freq_df = (\n",
    "    flat_recs.group_by(\"item_id\")\n",
    "    .agg(pl.count().alias(\"count\"))\n",
    "    .sort(\"count\", descending=True)\n",
    ")\n",
    "\n",
    "# 3. Join with book titles\n",
    "top_10_df = (\n",
    "    freq_df.head(15)\n",
    "    .join(books.select([\"item_id\", \"title\"]), on=\"item_id\", how=\"left\")\n",
    ")\n",
    "\n",
    "# 4. Plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(top_10_df[\"title\"].to_list()[::-1], top_10_df[\"count\"].to_list()[::-1])\n",
    "plt.xlabel(\"Frequency (times recommended)\")\n",
    "plt.ylabel(\"Book Title\")\n",
    "plt.title(\"Top 15 Most Recommended Books\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3df59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract first-position recommendation directly in Polars\n",
    "first_position_recs = test_res.select(\n",
    "    pl.col(\"item_knn_cosine_recs\").list.get(0).alias(\"item_id\")\n",
    ")\n",
    "\n",
    "# Count frequency\n",
    "freq_df = (\n",
    "    first_position_recs.group_by(\"item_id\")\n",
    "    .agg(pl.count().alias(\"count\"))\n",
    "    .sort(\"count\", descending=True)\n",
    ")\n",
    "\n",
    "# Join with books metadata\n",
    "top_10_df = (\n",
    "    freq_df.head(10)\n",
    "    .join(books.select([\"item_id\", \"title\"]), on=\"item_id\", how=\"left\")\n",
    "    .with_columns(pl.col(\"title\").fill_null(\"Unknown Title\"))\n",
    ")\n",
    "\n",
    "# Prepare data for plotting\n",
    "titles = top_10_df[\"title\"].to_list()\n",
    "counts = top_10_df[\"count\"].to_list()\n",
    "\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(titles, counts, color=\"skyblue\", edgecolor=\"black\")\n",
    "plt.xlabel(\"Book Titles\")\n",
    "plt.ylabel(\"First-Position Recommendation Frequency\")\n",
    "plt.title(\"Top 10 Books Recommended in First Position\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
